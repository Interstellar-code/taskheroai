# ========================================
# TaskHero AI Configuration Example
# ========================================
# Copy this file to .env and configure your settings
# Last updated: 2025-05-29

# ========================================
# OPENAI CONFIGURATION
# ========================================
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4
OPENAI_MAX_TOKENS=4000
OPENAI_TEMPERATURE=0.7
OPENAI_TOP_P=1.0
OPENAI_FREQUENCY_PENALTY=0.0
OPENAI_PRESENCE_PENALTY=0.0

# ========================================
# ANTHROPIC CONFIGURATION
# ========================================
# Get your API key from: https://console.anthropic.com/
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_MODEL=claude-sonnet-4-20250514
ANTHROPIC_MAX_TOKENS=4000
ANTHROPIC_TEMPERATURE=0.7
ANTHROPIC_TOP_P=1.0
ANTHROPIC_TOP_K=40

# ========================================
# OLLAMA CONFIGURATION (LOCAL AI)
# ========================================
# Install Ollama from: https://ollama.ai/
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=gemma3:4b
OLLAMA_MAX_TOKENS=4000
OLLAMA_TEMPERATURE=0.7
OLLAMA_TOP_P=0.95
OLLAMA_TOP_K=40

# ========================================
# DEEPSEEK CONFIGURATION
# ========================================
# Get your API key from: https://platform.deepseek.com/
DEEPSEEK_API_KEY=your_deepseek_api_key_here
DEEPSEEK_MODEL=deepseek-chat
DEEPSEEK_MAX_TOKENS=4000
DEEPSEEK_TEMPERATURE=0.7
DEEPSEEK_TOP_P=1.0

# ========================================
# OPENROUTER CONFIGURATION
# ========================================
# Get your API key from: https://openrouter.ai/keys
OPENROUTER_API_KEY=your_openrouter_api_key_here
OPENROUTER_MODEL=google/gemini-2.5-flash-preview-05-20
OPENROUTER_MAX_TOKENS=4000
OPENROUTER_TEMPERATURE=0.7
OPENROUTER_TOP_P=1.0
OPENROUTER_HTTP_REFERER=https://taskhero-ai.com
OPENROUTER_X_TITLE=TaskHeroAI

# ========================================
# AI TASK GENERATION SETTINGS
# ========================================
# Primary provider for task generation
AI_TASK_PROVIDER=ollama
AI_TASK_MODEL=gemma3:4b

# Fallback chain (comma-separated, in order of preference)
AI_PROVIDER_FALLBACK_CHAIN=deepseek,openai,anthropic,openrouter,ollama

# ========================================
# AI ROLE-SPECIFIC SETTINGS
# ========================================
# Chat functionality
AI_CHAT_PROVIDER=ollama
AI_CHAT_MODEL=gemma3:4b

# Agent buddy functionality
AI_AGENT_BUDDY_PROVIDER=ollama
AI_AGENT_BUDDY_MODEL=llama3.2:latest
AI_AGENT_BUDDY_MODEL_MAX_TOKENS=4096
AI_AGENT_BUDDY_MODEL_TEMPERATURE=0.7

# Description enhancement
AI_DESCRIPTION_PROVIDER=ollama
AI_DESCRIPTION_MODEL=codellama:latest

# Embedding generation
AI_EMBEDDING_PROVIDER=ollama
AI_EMBEDDING_MODEL=nomic-embed-text:latest

# ========================================
# OPTIMIZED MODEL CONFIGURATIONS
# ========================================
# These are the recommended models for different use cases:

# PREMIUM QUALITY MODELS (Best results, higher cost)
# - OpenAI: gpt-4
# - Anthropic: claude-opus-4-20250514
# - OpenRouter: google/gemini-2.5-pro-preview

# BALANCED PERFORMANCE MODELS (Good quality, moderate cost)
# - OpenAI: gpt-4-turbo-preview
# - Anthropic: claude-sonnet-4-20250514
# - OpenRouter: google/gemini-2.5-flash-preview-05-20
# - DeepSeek: deepseek-reasoner

# COST-EFFECTIVE MODELS (Good value, lower cost)
# - OpenAI: gpt-3.5-turbo
# - DeepSeek: deepseek-chat, deepseek-coder
# - OpenRouter: google/gemma-3-12b-it:free

# LOCAL MODELS (Free, privacy-focused)
# - Ollama: gemma3:4b (optimized for TaskHero)
# - Ollama: llama3.2:latest (general purpose)
# - Ollama: codellama:latest (code-focused)

# ========================================
# LEGACY CHAT SETTINGS (for compatibility)
# ========================================
CHAT_MODEL=gemma3:4b
CHAT_MODEL_MAX_TOKENS=4096
CHAT_MODEL_TEMPERATURE=0.7
CHAT_MODEL_TOP_K=40
CHAT_MODEL_TOP_P=0.95

DESCRIPTION_MODEL=codellama:latest
DESCRIPTION_MODEL_MAX_TOKENS=4096
DESCRIPTION_MODEL_TEMPERATURE=0.3
DESCRIPTION_MODEL_TOP_K=40
DESCRIPTION_MODEL_TOP_P=0.95

# ========================================
# EMBEDDING AND INDEXING SETTINGS
# ========================================
EMBEDDING_MODEL=nomic-embed-text:latest
EMBEDDING_API_DELAY_MS=0
EMBEDDING_CACHE_SIZE=1000
EMBEDDING_SIMILARITY_THRESHOLD=0.05

# ========================================
# APPLICATION SETTINGS
# ========================================
APP_DATA_DIR=./data
APP_DEBUG=false
APP_LOG_LEVEL=INFO
SITE_NAME=TaskHero AI Development
SITE_URL=http://localhost:3000

# ========================================
# PERFORMANCE SETTINGS
# ========================================
MAX_THREADS=16
PERFORMANCE_MODE=MEDIUM

# API delays (in milliseconds)
DESCRIPTION_API_DELAY_MS=0

# Intent detection settings
INTENT_DETECTION_MAX_TOKENS=4096
INTENT_DETECTION_TEMPERATURE=0.1
INTENT_DETECTION_TOP_K=40
INTENT_DETECTION_TOP_P=0.95

# ========================================
# USER INTERFACE SETTINGS
# ========================================
# Enable markdown rendering in responses
ENABLE_MARKDOWN_RENDERING=TRUE

# Show AI thinking blocks in responses
SHOW_THINKING_BLOCKS=FALSE

# Enable streaming mode for real-time responses
ENABLE_STREAMING_MODE=TRUE

# Enable automatic command execution (use with caution)
COMMANDS_YOLO=FALSE

# Enable chat logging to file
CHAT_LOGS=FALSE

# ========================================
# HTTP API SERVER SETTINGS
# ========================================
# Server configuration for web interface
HTTP_PORT=8000
HTTP_HOST=127.0.0.1

# Allow connections from any IP (security warning!)
HTTP_ALLOW_ALL_ORIGINS=FALSE

# Site information for provider analytics
SITE_URL=http://localhost:8000
SITE_NAME=TaskHero AI

# ========================================
# DEVELOPMENT AND DEBUG SETTINGS
# ========================================
# Enable debug logging
DEBUG_MODE=FALSE

# Log API requests and responses
LOG_API_REQUESTS=FALSE

# Enable verbose output
VERBOSE_LOGGING=FALSE

# Development environment flag
DEVELOPMENT_MODE=TRUE

# ========================================
# NOTES
# ========================================
# 1. For local development, use Ollama models (free, private)
# 2. For production, consider OpenAI or Anthropic for best quality
# 3. DeepSeek offers good balance of quality and cost
# 4. OpenRouter provides access to multiple models with one API key
# 5. Set AI_TASK_MODEL to your preferred model for task generation
# 6. The system will automatically optimize token usage based on the model
