#!/usr/bin/env python3
"""Test script for Task 089 - Enhanced Metadata Integration.

This script tests the enhanced metadata functionality including:
- Language detection
- Function signature extraction
- Import statement analysis
- Code pattern recognition
- Dependency mapping
- Migration functionality
"""

import json
import logging
import os
import sys
import tempfile
import time
from pathlib import Path
from typing import Dict

# Add the project root to the Python path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from mods.code.indexer import FileIndexer
from mods.code.migration import EmbeddingMigration, run_migration
from mods.code.analyzers import PythonAnalyzer, JavaScriptAnalyzer, MarkdownAnalyzer

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger("Task089Test")


def create_test_files(test_dir: Path) -> Dict[str, Path]:
    """Create test files for enhanced metadata analysis."""
    test_files = {}

    # Python test file
    python_content = '''"""Test Python module for enhanced metadata analysis."""

import os
import sys
from typing import List, Dict, Optional
from pathlib import Path

class TestClass:
    """A test class for demonstration."""

    def __init__(self, name: str):
        self.name = name

    def process_data(self, data: List[Dict]) -> Optional[str]:
        """Process data and return result."""
        if not data:
            return None

        results = []
        for item in data:
            if 'value' in item:
                results.append(str(item['value']))

        return ', '.join(results)

    @staticmethod
    def utility_function(x: int, y: int) -> int:
        """A utility function."""
        return x + y

async def async_function(url: str) -> Dict:
    """An async function example."""
    # Simulate async operation
    return {"status": "success", "url": url}

def main():
    """Main function."""
    test = TestClass("example")
    result = test.process_data([{"value": 1}, {"value": 2}])
    print(f"Result: {result}")

if __name__ == "__main__":
    main()
'''

    python_file = test_dir / "test_module.py"
    python_file.write_text(python_content, encoding='utf-8')
    test_files['python'] = python_file

    # JavaScript test file
    js_content = '''/**
 * Test JavaScript module for enhanced metadata analysis.
 */

import React from 'react';
import { useState, useEffect } from 'react';
import axios from 'axios';

class DataProcessor {
    constructor(name) {
        this.name = name;
    }

    processData(data) {
        return data.map(item => ({
            ...item,
            processed: true
        }));
    }

    static utilityMethod(a, b) {
        return a + b;
    }
}

const ApiService = {
    async fetchData(url) {
        try {
            const response = await axios.get(url);
            return response.data;
        } catch (error) {
            console.error('API Error:', error);
            throw error;
        }
    },

    postData: async (url, data) => {
        const response = await axios.post(url, data);
        return response.data;
    }
};

function TestComponent({ title, data }) {
    const [loading, setLoading] = useState(false);
    const [results, setResults] = useState([]);

    useEffect(() => {
        if (data) {
            const processor = new DataProcessor('test');
            setResults(processor.processData(data));
        }
    }, [data]);

    const handleClick = () => {
        setLoading(true);
        // Handle click logic
    };

    return (
        <div>
            <h1>{title}</h1>
            {loading ? <p>Loading...</p> : <ul>{results.map(item => <li key={item.id}>{item.name}</li>)}</ul>}
        </div>
    );
}

export { DataProcessor, ApiService };
export default TestComponent;
'''

    js_file = test_dir / "test_component.js"
    js_file.write_text(js_content, encoding='utf-8')
    test_files['javascript'] = js_file

    # Markdown test file
    md_content = '''# Test Documentation

This is a test markdown file for enhanced metadata analysis.

## Overview

This document demonstrates various markdown features:

- Lists
- Links
- Code blocks
- Tables

### Code Examples

```python
def example_function():
    return "Hello, World!"
```

```javascript
function exampleFunction() {
    return "Hello, World!";
}
```

### Links and References

- [Python Documentation](https://docs.python.org/)
- [JavaScript Guide](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide)
- [Internal Link](#overview)

### Table Example

| Feature | Status | Notes |
|---------|--------|-------|
| Functions | OK | Working |
| Classes | OK | Working |
| Imports | OK | Working |

### Task List

- [x] Implement basic functionality
- [ ] Add error handling
- [ ] Write tests
- [ ] Update documentation

## Conclusion

This document serves as a test case for markdown analysis capabilities.
'''

    md_file = test_dir / "test_doc.md"
    md_file.write_text(md_content, encoding='utf-8')
    test_files['markdown'] = md_file

    return test_files


def test_analyzers():
    """Test individual analyzers."""
    logger.info("ðŸ§ª Testing individual analyzers...")

    with tempfile.TemporaryDirectory() as temp_dir:
        test_dir = Path(temp_dir)
        test_files = create_test_files(test_dir)

        # Test Python analyzer
        logger.info("Testing Python analyzer...")
        python_analyzer = PythonAnalyzer()
        python_content = test_files['python'].read_text()
        python_result = python_analyzer.analyze_content(python_content, test_files['python'])

        assert len(python_result['functions']) > 0, "Should find functions in Python file"
        assert len(python_result['classes']) > 0, "Should find classes in Python file"
        assert len(python_result['imports']) > 0, "Should find imports in Python file"
        assert 'object_oriented' in python_result['patterns'], "Should detect OOP pattern"
        assert 'asynchronous' in python_result['patterns'], "Should detect async pattern"

        logger.info(f"âœ… Python analyzer found: {len(python_result['functions'])} functions, "
                   f"{len(python_result['classes'])} classes, {len(python_result['imports'])} imports")

        # Test JavaScript analyzer
        logger.info("Testing JavaScript analyzer...")
        js_analyzer = JavaScriptAnalyzer()
        js_content = test_files['javascript'].read_text()
        js_result = js_analyzer.analyze_content(js_content, test_files['javascript'])

        assert len(js_result['functions']) > 0, "Should find functions in JavaScript file"
        assert len(js_result['classes']) > 0, "Should find classes in JavaScript file"
        assert len(js_result['imports']) > 0, "Should find imports in JavaScript file"
        assert len(js_result['exports']) > 0, "Should find exports in JavaScript file"

        logger.info(f"âœ… JavaScript analyzer found: {len(js_result['functions'])} functions, "
                   f"{len(js_result['classes'])} classes, {len(js_result['imports'])} imports")

        # Test Markdown analyzer
        logger.info("Testing Markdown analyzer...")
        md_analyzer = MarkdownAnalyzer()
        md_content = test_files['markdown'].read_text()
        md_result = md_analyzer.analyze_content(md_content, test_files['markdown'])

        assert len(md_result['exports']) > 0, "Should find headings in Markdown file"
        assert len(md_result['imports']) > 0, "Should find links in Markdown file"
        assert 'code_blocks' in md_result['patterns'], "Should detect code blocks"
        assert 'tables' in md_result['patterns'], "Should detect tables"

        logger.info(f"âœ… Markdown analyzer found: {len(md_result['exports'])} headings, "
                   f"{len(md_result['imports'])} links, {len(md_result['patterns'])} patterns")


def test_enhanced_indexing():
    """Test enhanced metadata indexing."""
    logger.info("ðŸ” Testing enhanced metadata indexing...")

    with tempfile.TemporaryDirectory() as temp_dir:
        test_dir = Path(temp_dir)
        test_files = create_test_files(test_dir)

        # Create indexer with enhanced metadata enabled
        indexer = FileIndexer(str(test_dir))

        # Index the test directory
        indexed_files = indexer.index_directory()

        assert len(indexed_files) > 0, "Should index test files"

        # Check enhanced metadata
        for metadata in indexed_files:
            assert metadata.metadata_version == 2, "Should have version 2 metadata"

            if metadata.enhanced_info:
                assert metadata.enhanced_info.language != "unknown", "Should detect language"
                assert metadata.enhanced_info.file_type != "unknown", "Should detect file type"
                assert metadata.enhanced_info.lines_of_code > 0, "Should count lines of code"

                logger.info(f"âœ… {metadata.name}: {metadata.enhanced_info.language} "
                           f"({metadata.enhanced_info.file_type}), "
                           f"{metadata.enhanced_info.lines_of_code} LOC, "
                           f"complexity: {metadata.enhanced_info.complexity_score:.2f}")

            if metadata.code_analysis:
                total_functions = len(metadata.code_analysis.functions)
                total_classes = len(metadata.code_analysis.classes)
                total_imports = len(metadata.code_analysis.imports)

                logger.info(f"   Code analysis: {total_functions} functions, "
                           f"{total_classes} classes, {total_imports} imports")

        logger.info(f"âœ… Enhanced indexing completed for {len(indexed_files)} files")


def test_migration():
    """Test migration functionality."""
    logger.info("ðŸ”„ Testing migration functionality...")

    with tempfile.TemporaryDirectory() as temp_dir:
        test_dir = Path(temp_dir)
        test_files = create_test_files(test_dir)

        # Create legacy embeddings (version 1)
        embeddings_dir = test_dir / ".index" / "embeddings"
        embeddings_dir.mkdir(parents=True)

        # Create a legacy embedding file
        legacy_embedding = {
            "path": str(test_files['python'].relative_to(test_dir)),
            "chunks": [{"text": "test content", "type": "generic_text"}],
            "embeddings": [[0.1, 0.2, 0.3]],
            "metadata": {
                "version": 1,
                "timestamp": time.time(),
                "file_path": str(test_files['python']),
                "graphiti_compatible": True
            }
        }

        legacy_file = embeddings_dir / "test_module_py.json"
        with open(legacy_file, 'w') as f:
            json.dump(legacy_embedding, f, indent=2)

        # Run migration
        migration_results = run_migration(str(test_dir))

        assert migration_results['migrated'] > 0, "Should migrate at least one file"
        assert migration_results['backup_created'], "Should create backup"

        # Verify migration
        migration = EmbeddingMigration(embeddings_dir)
        verification = migration.verify_migration()

        assert verification['enhanced_files'] > 0, "Should have enhanced files after migration"

        logger.info(f"âœ… Migration completed: {migration_results['migrated']} files migrated")
        logger.info(f"âœ… Verification: {verification['enhanced_files']}/{verification['total_files']} "
                   f"files have enhanced metadata")


def test_performance():
    """Test performance of enhanced metadata extraction."""
    logger.info("âš¡ Testing performance...")

    with tempfile.TemporaryDirectory() as temp_dir:
        test_dir = Path(temp_dir)

        # Create multiple test files
        for i in range(10):
            test_file = test_dir / f"test_{i}.py"
            test_file.write_text(f'''
def function_{i}():
    """Function {i}."""
    return {i}

class Class_{i}:
    """Class {i}."""
    def method_{i}(self):
        return function_{i}()
''', encoding='utf-8')

        # Test indexing performance
        start_time = time.time()
        indexer = FileIndexer(str(test_dir))
        indexed_files = indexer.index_directory()
        end_time = time.time()

        indexing_time = end_time - start_time
        files_per_second = len(indexed_files) / indexing_time if indexing_time > 0 else 0

        logger.info(f"âœ… Performance test: {len(indexed_files)} files indexed in {indexing_time:.3f}s "
                   f"({files_per_second:.1f} files/sec)")

        # Verify performance is acceptable (should be under 5 seconds per file including AI processing)
        avg_time_per_file = indexing_time / len(indexed_files) if indexed_files else 0
        assert avg_time_per_file < 5.0, f"Indexing too slow: {avg_time_per_file:.3f}s per file"


def main():
    """Run all tests for Task 089."""
    logger.info("ðŸš€ Starting Task 089 - Enhanced Metadata Integration Tests")

    try:
        # Test individual analyzers
        test_analyzers()

        # Test enhanced indexing
        test_enhanced_indexing()

        # Test migration
        test_migration()

        # Test performance
        test_performance()

        logger.info("ðŸŽ‰ All Task 089 tests passed successfully!")

        # Print summary
        print("\n" + "="*60)
        print("TASK 089 - ENHANCED METADATA INTEGRATION - TEST SUMMARY")
        print("="*60)
        print("âœ… Language Detection - Working")
        print("âœ… Function Signature Extraction - Working")
        print("âœ… Import Statement Analysis - Working")
        print("âœ… Code Pattern Recognition - Working")
        print("âœ… Enhanced Metadata Storage - Working")
        print("âœ… Migration Functionality - Working")
        print("âœ… Performance Optimization - Working")
        print("âœ… Backward Compatibility - Working")
        print("="*60)
        print("ðŸŽ¯ Task 089 implementation is ready for production!")

        return True

    except Exception as e:
        logger.error(f"âŒ Task 089 tests failed: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
